---
title: "STA257"
author: "Neil Montgomery | HTML is official | PDF versions good for in-class use only"
date: "Last edited: `r format(Sys.time(), '%Y-%m-%d %H:%M')`"
output: 
  ioslides_presentation: 
    css: '../styles.css' 
    widescreen: true 
    transition: 0.001
header-includes:
- \usepackage{cancel}
---
\newcommand\given[1][]{\:#1\vert\:}
\newcommand\P[1]{P{\left(#1\right)}}
\newcommand\F[1]{F_{\tiny{#1}}}
\newcommand\f[1]{f_{\tiny{#1}}}
\newcommand\p[1]{p_{\tiny{#1}}}

# DOFORV - distributions of functions of (continuous) random variables - continued

## DOFORV method 2 - direct "theorem"

I am delighted that the book downplays this method as not as easy to use. Nor do I recommend it for practical use.

**The cdf approach is usually the cleanest and least error prone.**

Theorem: Given $X$ with density $\f{X}(x)$ and $g$ monotone and differentiable with inverse $g^{-1}$ where $\f{X}(x) > 0$, let $Y=g(X)$. Then:
$$\f{Y}(y) = \f{X}(g^{-1}(y))\left|\frac{d}{dy}g^{-1}(y)\right|$$
This theorem can be extended to non-monotonic $g$. 

## DOFORV - three proofs

The theorem can be proved using the cdf approach and two other ways that are straight outta calculus.

The proofs indeed all look very similar. 

Proof 2: uses the "change of variables" method from integration (emphasizes my advice to always think of a density as living in an integral.)

Proof 3: uses the fundamental theorem of calculus (note: I never bothered with this one.)

## added after class - Proof 2 - change of variables - I

In this proof I emphasize the point that the *density lives in a definite integral* and that the distribution of $Y=g(X)$ is obtained via a *change of variables* $y=g(x)$ inside the definite integral. 

For $a < b$ the distribution of $X$ with density $\f{X}$ is characterized by:

$$\int_a^b \f{X}(x)\,dx,$$
which after the change of variable $y = g(x)$ becomes:
$$\int_{g^{-1}(a)}^{g^{-1}(b)} \f{X}(g^{-1}(y))\,\frac{d}{dy}g^{-1}(y)\,dy$$

## added after class - Proof 2 - change of variables - II

Note that when $g$ is decreasing, so will $g^{-1}$, which will mean $g^{-1}(a) > g^{-1}(b)$ and in that case the integral would be negative. So:

$$\begin{align}\int_a^b \f{X}(x)\,dx &= \begin{cases}
\int_{g^{-1}(a)}^{g^{-1}(b)} \f{X}(g^{-1}(y))\,\frac{d}{dy}g^{-1}(y)\,dy &: g \text{ increasing}\\
-\int_{g^{-1}(a)}^{g^{-1}(b)} \f{X}(g^{-1}(y))\,\frac{d}{dy}g^{-1}(y)\,dy &: g \text{ decreasing}\end{cases}\\
&=\int_{g^{-1}(a)}^{g^{-1}(b)} \f{X}(g^{-1}(y))\,\left|\frac{d}{dy}g^{-1}(y)\right|\,dy
\end{align}$$
The integrand is the density for $Y$.

## a seemingly strange example { .build }

The techniques apply to any continuous r.v. $X$ and to any differentiable, invertible $g(x)$.

So let's consider $X \sim \text{Exp}(\lambda)$ and let $g(x) = 1 - e^{-\lambda x}$. It turns out $Y \sim \text{Unif}[0,1]$.

The function $g$ was not chosen by accident---it it precisely the cdf $\F{X}(x)$ of $X$. 

Theorem: If $X$ is continuous and has cdf $\F{X}(x)$ then $Y = \F{X}(X)$ will have a uniform distribution on $[0,1]$.

Proof: ...

## another DOFORV example

Suppose $X\sim\text{Gamma}(\alpha, \lambda)$ and

$$g(x) = \begin{cases}\frac{1}{x} &: x > 0,\\
0 &: \text{otherwise.}\end{cases}$$ 

Determine the distribution of $Y = g(X)$ by finding its density.

